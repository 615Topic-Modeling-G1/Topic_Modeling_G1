---
title: "Topic Modeling Runci"
author: "Runci Hu"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(stringr)
library(tidyr)
library(tidytext)
library(tidyverse)
library(topicmodels)
library(stopwords)
library(ggplot2)
library(DescTools)
```

```{r}
imdb <- read.csv("~/Desktop/IMDB Dataset.csv")
```

```{r}
imdb <- imdb %>% select(-sentiment)
imdb_df <- tibble(review = 1:50000, sentence = imdb[,1])
imdb_df <- imdb_df[1:1000,]
text_df <- imdb_df %>% slice_sample(n = 100, replace = FALSE)
```

# Bigram
```{r}
token_bigram <- text_df %>%
  unnest_tokens(bigram,
                sentence, 
                token = "ngrams",
                n = 2,
                to_lower=TRUE) %>%
  count(review,bigram,sort = TRUE)%>%
  filter(!is.na(bigram))

## create a stop word vector, drop the attribute, drop the attribute
stop <-  unlist(stop_words[,1])
stop <- StripAttr(stop)
stop <- c(stop, "br")

## split the bigram list into two columns
check <-  token_bigram %>% separate(bigram, 
                                    sep= " ", 
                                    c("w1", "w2"))

## check both words individually agains stop word lists
a <- check$w1 %in% stop
b <- check$w2 %in% stop
## the bigram is included only if neither of the single words is a stop word
remove <- (a|b)
## to make it easier to see create a data frame
d <- cbind(token_bigram, a, b, remove)

d <- d %>% filter(d$a !="br" && d$b != "br")

## create an index of bigram
f <- which(d$remove == FALSE)
## use the index to make a list of bigrams
g <- d$bigram[f]

(review_separated <- token_bigram %>%  
  separate(bigram, into = c("word1", "word2"), sep = " ")
)

review_united <- review_separated %>%
  filter(!word1 %in% c('br'),
         !word2 %in% c('br')) %>%
  unite(bigram, c(word1, word2), sep = " ")

total_bigram <- review_united %>%
  group_by(review) %>%
  summarize(total = sum(n))

review_bigram <- left_join(review_united, total_bigram)
rm(token_bigram, review_separated, review_united, total_bigram)
```

# frequency 
```{r}
freq_by_rank_bi <- review_bigram %>% 
  group_by(review) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

freq_by_rank_bi %>% 
  ggplot(aes(rank, `term frequency`, color = review)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()
```

# tf-idf
```{r}
review_tf_idf_bi <- review_bigram %>%
  bind_tf_idf(bigram, review, review)
#look at terms with high tf-idf in reviews.
review_tf_idf_bi <- review_tf_idf_bi %>%
  select(-total) %>%
  arrange(desc(tf-idf))

review_tf_idf_bi
```

# select bigram stop words 
```{r}
stopwords <- as.vector(review_tf_idf_bi$bigram)
u1 <- unique(stopwords)
stopwords <- data.frame(u1)
sw <- as.character(stopwords$u1[1:10000])
sw <- tibble(sw)
head(sw)
```
# single-word stop words
```{r}
imdb <- imdb  %>%  mutate(docs = c(1:length(imdb$review)))
data(stop_words)
stop_words <- rbind(stop_words,c("br", "Smart"))
```


# LDA
```{r}
imdb_dtm <- imdb %>%
  unnest_tokens(word, review) %>%
  anti_join(stop_words)%>%
  count(docs, word) %>%
  cast_dtm(docs, word, n)

imdb_lda <- LDA(imdb_dtm, k = 10, control = list(seed = 2022))
imdb_topics <- tidy(imdb_lda, matrix = "beta")
imdb_topics

imdb_top_terms <- imdb_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

imdb_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()

beta_wide <- imdb_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))
```

# Document Classification
```{r}
ap_documents <- tidy(imdb_lda, matrix = "gamma")
# check the per-document-per-topic probabilities using gamma
ap_documents <- ap_documents %>%
  separate(document, c("title"),sep = "_", convert = TRUE)
ap_documents
```

```{r, warning=FALSE, message=FALSE}
ggplot(ap_documents, aes(x = gamma , fill = as.factor(topic))) + 
  geom_histogram()+
  facet_wrap(~topic, ncol = 3) + 
  scale_y_log10() +
  labs(title = "per-document-per-topic probabilities",
       y = "documents number", x= "gamma")
```


```{r}
ggplot(ap_documents, aes(factor(topic),gamma )) + 
  geom_boxplot() +
  labs(title = "per-document-per-topic probabilities",
       y = "gamma", x= "topic")
```

