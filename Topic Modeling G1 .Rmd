---
title: "Topic Modeling Runci"
author: "Runci Hu"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(stringr)
library(tidyr)
library(tidytext)
library(tidyverse)
library(topicmodels)
library(stopwords)
library(ggplot2)
library(DescTools)

imdb <- read.csv("~/Desktop/IMDB Dataset.csv")


# text_df <- tibble(review = 1:50000, sentence = imdb[,1]) 
# text_df <- text_df[1:200,]

```

```{r}
imdb <- imdb %>% select(-sentiment)
# imdb_df <- tibble(review = 1:50000, sentence = imdb[,1])
imdb_df <- imdb %>% slice_sample(n = 100, replace = FALSE)
```

#Bigram
```{r}
token_bigram <- imdb_df %>%
  unnest_tokens(bigram,
                review,
                token = "ngrams",
                n = 2,
                to_lower=TRUE) %>%
  filter(!is.na(bigram))

## create a stop word vector
stop <-  unlist(stop_words[,1])
## drop the attribute
stop <- StripAttr(stop)
## add to the stop list
stop <- c(stop, "br")
## split the bigram list into two columns
check <-  token_bigram %>% separate(bigram, 
                                    sep= " ", 
                                    c("w1", "w2"))

## check both words individually agains stop word lists
a <- check$w1 %in% stop
b <- check$w2 %in% stop
## the bigram is included only if neither 
## of the single words is a stop word
remove <- (a|b)
## to make it easier to see create a data frame
d <- cbind(token_bigram, a, b, remove)

d <- d %>% filter(d$a !="br" && d$b != "br")

## create an index of bigram
f <- which(d$remove == FALSE)
## use the index to make a list of bigrams
g <- d$bigram[f]

(review_separated <- token_bigram %>%  
  separate(bigram, into = c("word1", "word2"), sep = " ")
)
review_united <- review_separated %>%
  filter(!word1 %in% c('br'),
         !word2 %in% c('br')) %>%
  unite(bigram, c(word1, word2), sep = " ")

freq_bigram <- token_bigram %>% count(bigram,sort = TRUE)

# total_bigram <- review_united %>%
#   group_by(review) %>%
#   summarize(total = sum(n))

review_bigram <- left_join(review_united, token_bigram)
rm(token_bigram, review_separated, review_united, token_bigram)
```






```{r}
imdb <- imdb  %>%  mutate(docs = c(1:length(imdb$review)))

data(stop_words)
stop_words <- rbind(stop_words,c("br", "Smart"))
```



# LDA
```{r}
imdb_dtm <- imdb %>%
  unnest_tokens(word, review) %>%
  anti_join(stop_words)%>%
  count(docs, word) %>%
  cast_dtm(docs, word, n)

imdb_lda <- LDA(imdb_dtm, k = 10, control = list(seed = 2022))
imdb_topics <- tidy(imdb_lda, matrix = "beta")
imdb_topics

imdb_top_terms <- imdb_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

imdb_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()

beta_wide <- imdb_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))
```

```{r}
##tfidf 
```

